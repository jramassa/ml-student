{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "**Fiche d'exercice n°1**\n",
        "\n",
        "Cette fiche d'exercices doit permettre de :\n",
        "- s'entraîner au devoir de janvier\n",
        "- compléter votre culture dans le domaine\n",
        "\n",
        "La correction sera mise à disposition autour du 11/11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "**Question 1** Nous avons vu qu'il était impossible de séparer les nuages de points du TP1/partie I/B avec un perceptron une couche. Mais c'est parce que nous nous sommes limités à deux prédicteurs, l'abscisse $x$ et l'ordonnée $y$. Quels autres prédicteurs peut-on utiliser pour résoudre le problème sans ajouter de couches au perceptron ?\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les prédicteurs que nous pouvons également utiliser seraient une combinaison linéaire des deux premiers. Par exemple, la somme de x et y."
      ],
      "metadata": {
        "id": "1ffltojcYmHG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4B0YORSkz1G"
      },
      "source": [
        "**Question 2** A quel modèle statistique correspond un perceptron à une couche avec une fonction d'activation sigmoïde ?\n",
        "Citer une bibliothèque python qui permet d'appliquer ce modèle à un jeu de données."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch bibliothèque permettant d'appliquer ce modèle"
      ],
      "metadata": {
        "id": "fPBCBrPZY97d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUCeXqO7icjq"
      },
      "source": [
        "**Question 3** Combien un VGG16 contient-il de paramètres dans les couches de convolutions ? Dans les couches complètement connectées ?\n",
        "Appuyer par un bout de code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn   # pre-defined layers\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# to load pre-trained models on ImageNet:\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "print(model)\n",
        "\n",
        "conv_weights = 0\n",
        "\n",
        "linear_weights = 0\n",
        "\n",
        "for module in model.modules():\n",
        "  if isinstance(module, nn.Conv2d):\n",
        "    for parameter in module.parameters():\n",
        "      conv_weights += torch.numel(parameter)\n",
        "  if isinstance(module, nn.Linear):\n",
        "    for parameter in module.parameters():\n",
        "      linear_weights += torch.numel(parameter)\n",
        "\n",
        "print(conv_weights)\n",
        "print(linear_weights)\n"
      ],
      "metadata": {
        "id": "kJYLstZba9dN",
        "outputId": "e62b62c2-3e28-48ef-fd43-8a2c51c6116b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "14714688\n",
            "123642856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjBFb83GmuEY"
      },
      "source": [
        "**Question 4** Visualiser la première couche d'un VGG entraîné sur ImageNet. Commenter."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_layer = model.features[0].weight.data\n",
        "print(first_layer.shape)\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(first_layer.shape[0]):\n",
        "    plt.subplot(8, 8, i+1) #\n",
        "    plt.imshow(first_layer[i, 1, :, :], cmap='seismic')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IInv08pzdjAK",
        "outputId": "d1059f35-e365-4c23-c92b-55b160befcf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 3, 3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 64 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracteurs de contours et détecteurs de particularités (lignes...)"
      ],
      "metadata": {
        "id": "7j0o9RTIh7IX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfcRiTA2mzrp"
      },
      "source": [
        "**Question 5** Quel est l'effet d'un dropout sur les couches complètement connectées ? Illustrer sur un perceptron à une couche avec quelques lignes de codes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dropout permet de geler certains neurones pour éviter le surapprentissage."
      ],
      "metadata": {
        "id": "sfhK7k4diYtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class P1(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(P1, self).__init__()\n",
        "        self.fc = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Dot product and bias\n",
        "        x = self.fc(x)\n",
        "        # Activation\n",
        "        x = x.sigmoid()\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Vector of \"probabilities\" (cat: concatenation)\n",
        "        x = torch.cat((x, 1 - x), dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def linear(x):\n",
        "  return nn.Linear(5, 3)(x)\n",
        "\n",
        "def dp(x):\n",
        "  return F.dropout(x, p = 0.5)\n",
        "\n",
        "a = torch.tensor([[4., 7.1, -3., 8.3, 10.]])\n",
        "\n",
        "y = linear(a)\n",
        "\n",
        "print(y)\n",
        "\n",
        "output = dp(y)\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "CqknqlLLio5y",
        "outputId": "fbd19ccb-444f-43d3-9b74-e99711caa3be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.2291, -7.5247, -5.1133]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-8.4582, -0.0000, -0.0000]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-xSNmhpm1LB"
      },
      "source": [
        "**Problème 1** Classification avec cibles bruitées\n",
        "\n",
        "Les utilisateurs du Machine Learning font souvent face à un problème de qualité des cibles.\n",
        "Dans ce court problème, on se propose de mesurer l'effet de cibles bruitées sur les performances en généralisation d'un CNN.\n",
        "\n",
        "\n",
        "Pour une comparaison propre, nous allons d'abord scinder en trois jeux le dataset MNIST :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NozoimIfmkjc"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torch\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "root = '/content/drive/MyDrive/TP_ENM/data'\n",
        "\n",
        "#Définition des jeux d'apprentissage:\n",
        "tr=torchvision.transforms.Compose([\n",
        "   torchvision.transforms.ToTensor(),\n",
        "   torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "   ])\n",
        "\n",
        "\n",
        "ds_trainval = datasets.MNIST(root='MNIST', download=True, train=True)\n",
        "ds_test = datasets.MNIST(root='MNIST', download=True, train=False)\n",
        "\n",
        "\n",
        "\n",
        "len_trainval = len(ds_trainval)\n",
        "len_train = round(0.8 * len_trainval)\n",
        "len_val = len_trainval - len_train\n",
        "subset_train, subset_val = random_split(ds_trainval,\n",
        "                                [len_train, len_val],\n",
        "                                generator=torch.Generator().manual_seed(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXc4EkTz0IFM"
      },
      "outputs": [],
      "source": [
        "#Split aléatoire en deux datasets (80% train, 20% val):\n",
        "class SubDataset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOosklok0Lik"
      },
      "outputs": [],
      "source": [
        "ds = {}\n",
        "ds['train'] = SubDataset(subset_train, tr)\n",
        "ds['val'] = SubDataset(subset_val, tr)\n",
        "ds['test'] = ds_test\n",
        "loader = {x : DataLoader(ds[x], batch_size=32, shuffle=True, num_workers = 2) for x in ds.keys()}\n",
        "\n",
        "TrainLoader = loader['train']\n",
        "inputs, labels = next(iter(TrainLoader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ds['train']))\n",
        "\n",
        "print(len(ds['val']))\n",
        "\n",
        "print(len(ds['test']))"
      ],
      "metadata": {
        "id": "Sfv-ZsXdlCTc",
        "outputId": "d722b4c5-639c-45c7-bc89-9b4ad8da71f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48000\n",
            "12000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtQObOlvsZmK"
      },
      "source": [
        "**Question 6**  Quelles sont les tailles des différents jeux de données ? A quoi sert-il de fixer le générateur de nombres aléatoires dans random_split ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPUp4Ckqsvwq"
      },
      "source": [
        "**Question 7** Reprendre le CNN du TP2/partie1 et la fonction train_model_gpu vue au TP2/partie2.\n",
        "- Ajouter une procédure de sélection de modèle à partir des performances sur le jeu de validation.\n",
        "- Coder une fonction test_model_gpu() qui calcule la justesse sur le jeu de test.\n",
        "- Faire tourner l'apprentissage sur 50 époques, avec l'optimiser ADAM, paramétré de manière standard.\n",
        "\n",
        "Quelles sont les performances sur le jeu de test du modèle sélectionné ? \\\\\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\") # 0 is the index of the GPU\n",
        "  print(torch.cuda.get_device_name(device))\n",
        "else:\n",
        "  print('Change the runtime type to GPU')"
      ],
      "metadata": {
        "id": "Jy1pNZ7envOX",
        "outputId": "ab5cf3dc-67ea-41bb-dc2d-00b109793213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import copy\n",
        "\n",
        "N = 490\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(N, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, N)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        # Here, the log is applied after the softmax:\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "dataset_sizes = {'train':len(ds['train']), 'val':len(ds['val']), 'test':len(ds['test'])}\n",
        "\n",
        "def train_model_gpu(model, loss_fn, optimizer, num_epochs=1):\n",
        "    # Record the starting time\n",
        "    since = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Iterate through training and validation phases\n",
        "        for phase in ['train', 'val']:\n",
        "            # Set the model to training mode during the training phase, and evaluation mode during validation\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Initialize counters for loss and correct predictions\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate through batches in the data loader\n",
        "            for inputs, labels in loader[phase]:\n",
        "                # Move inputs and labels to the specified device (GPU)\n",
        "                ### BEGIN SOLUTION\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Zero the gradients in the optimizer (same as in train_model())\n",
        "                ### BEGIN SOLUTION\n",
        "                optimizer.zero_grad()\n",
        "                ### END SOLUTION\n",
        "                # Forward pass: compute model outputs and predictions (same as in train_model())\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ### BEGIN SOLUTION\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    ### END SOLUTION\n",
        "                    # Backward pass and optimization step if in the training phase (same as in train_model())\n",
        "                    ### BEGIN SOLUTION\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    ### END SOLUTION\n",
        "                # Update counters\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                acc = torch.sum(preds == labels.data)\n",
        "                # The 'acc' tensor is distributed across different parts of the GPU\n",
        "                # Gather the 'acc' tensor on the CPU before accumulation\n",
        "                # running_corrects += ...\n",
        "                ### BEGIN SOLUTION\n",
        "                running_corrects += acc.cpu()\n",
        "                ### END SOLUTION\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # At the end of each epoch, save the best model:\n",
        "            if phase == \"val\" and epoch_acc > best_val_acc:\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    # Calculate and print the total training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    # Return the trained model\n",
        "    return model, best_model_wts\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn =  nn.CrossEntropyLoss()\n",
        "\n",
        "model, best_model_wts = train_model_gpu(model, loss_fn, optimizer, num_epochs=50)\n"
      ],
      "metadata": {
        "id": "0cqO3zAdnLvZ",
        "outputId": "2ec63743-cccf-42b7-b0ad-988f2cb3232d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.3686 Acc: 88.46%\n",
            "val Loss: 0.0823 Acc: 97.56%\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.1514 Acc: 95.55%\n",
            "val Loss: 0.0641 Acc: 98.05%\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1171 Acc: 96.48%\n",
            "val Loss: 0.0545 Acc: 98.35%\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1016 Acc: 97.00%\n",
            "val Loss: 0.0490 Acc: 98.57%\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0911 Acc: 97.31%\n",
            "val Loss: 0.0460 Acc: 98.63%\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0841 Acc: 97.47%\n",
            "val Loss: 0.0395 Acc: 98.72%\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0746 Acc: 97.73%\n",
            "val Loss: 0.0497 Acc: 98.58%\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0712 Acc: 97.80%\n",
            "val Loss: 0.0468 Acc: 98.67%\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0694 Acc: 97.85%\n",
            "val Loss: 0.0384 Acc: 98.93%\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0629 Acc: 98.10%\n",
            "val Loss: 0.0384 Acc: 98.89%\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0640 Acc: 98.00%\n",
            "val Loss: 0.0373 Acc: 98.95%\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0590 Acc: 98.16%\n",
            "val Loss: 0.0437 Acc: 98.88%\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0566 Acc: 98.13%\n",
            "val Loss: 0.0343 Acc: 98.99%\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0541 Acc: 98.25%\n",
            "val Loss: 0.0458 Acc: 98.79%\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0538 Acc: 98.32%\n",
            "val Loss: 0.0418 Acc: 98.78%\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0522 Acc: 98.29%\n",
            "val Loss: 0.0446 Acc: 98.85%\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0495 Acc: 98.42%\n",
            "val Loss: 0.0438 Acc: 98.84%\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0481 Acc: 98.43%\n",
            "val Loss: 0.0427 Acc: 98.84%\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0485 Acc: 98.39%\n",
            "val Loss: 0.0516 Acc: 98.70%\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0458 Acc: 98.56%\n",
            "val Loss: 0.0397 Acc: 98.98%\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0445 Acc: 98.53%\n",
            "val Loss: 0.0400 Acc: 98.94%\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0427 Acc: 98.57%\n",
            "val Loss: 0.0445 Acc: 98.84%\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0398 Acc: 98.66%\n",
            "val Loss: 0.0427 Acc: 98.90%\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0418 Acc: 98.65%\n",
            "val Loss: 0.0384 Acc: 98.98%\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0374 Acc: 98.78%\n",
            "val Loss: 0.0418 Acc: 99.02%\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0381 Acc: 98.78%\n",
            "val Loss: 0.0388 Acc: 99.06%\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0395 Acc: 98.75%\n",
            "val Loss: 0.0419 Acc: 99.04%\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0381 Acc: 98.74%\n",
            "val Loss: 0.0443 Acc: 98.98%\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0396 Acc: 98.72%\n",
            "val Loss: 0.0432 Acc: 99.07%\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0370 Acc: 98.76%\n",
            "val Loss: 0.0417 Acc: 98.98%\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0360 Acc: 98.81%\n",
            "val Loss: 0.0441 Acc: 99.05%\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0366 Acc: 98.78%\n",
            "val Loss: 0.0466 Acc: 98.93%\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0338 Acc: 98.87%\n",
            "val Loss: 0.0442 Acc: 98.98%\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0354 Acc: 98.86%\n",
            "val Loss: 0.0507 Acc: 98.98%\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0362 Acc: 98.80%\n",
            "val Loss: 0.0450 Acc: 99.00%\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0335 Acc: 98.93%\n",
            "val Loss: 0.0475 Acc: 99.03%\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0345 Acc: 98.80%\n",
            "val Loss: 0.0403 Acc: 99.05%\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0323 Acc: 98.93%\n",
            "val Loss: 0.0476 Acc: 98.95%\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0320 Acc: 98.88%\n",
            "val Loss: 0.0602 Acc: 98.98%\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0327 Acc: 98.89%\n",
            "val Loss: 0.0509 Acc: 98.94%\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0333 Acc: 98.90%\n",
            "val Loss: 0.0569 Acc: 98.81%\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0282 Acc: 99.02%\n",
            "val Loss: 0.0552 Acc: 98.97%\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0340 Acc: 98.89%\n",
            "val Loss: 0.0517 Acc: 99.02%\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0337 Acc: 98.89%\n",
            "val Loss: 0.0517 Acc: 98.98%\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0310 Acc: 98.98%\n",
            "val Loss: 0.0517 Acc: 98.98%\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0316 Acc: 98.97%\n",
            "val Loss: 0.0445 Acc: 99.03%\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0310 Acc: 98.98%\n",
            "val Loss: 0.0540 Acc: 98.90%\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0282 Acc: 99.05%\n",
            "val Loss: 0.0504 Acc: 99.00%\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0298 Acc: 99.00%\n",
            "val Loss: 0.0463 Acc: 99.03%\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0308 Acc: 98.99%\n",
            "val Loss: 0.0526 Acc: 98.96%\n",
            "Training complete in 15m 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "TestLoader = loader['test']\n",
        "\n",
        "# def test_model_gpu(model, loss_fn):\n",
        "#   phase = 'test'\n",
        "#   model.eval()\n",
        "\n",
        "#   running_loss = 0.0\n",
        "#   running_corrects = 0\n",
        "#   for input, label in tqdm(loader[phase]):\n",
        "#     input = input.to(device)\n",
        "#     label = label.to(device)\n",
        "#     output = model(input)\n",
        "#     loss = loss_fn(output, label)\n",
        "#     _, preds = torch.max(output, 1)\n",
        "#     running_loss += loss.item() * inputs.size(0)\n",
        "#     acc = torch.sum(preds == labels.data)\n",
        "#     acc = acc.to('cpu')\n",
        "#     running_corrects += acc\n",
        "#   loss_global = running_loss / dataset_sizes['test']\n",
        "#   acc_global = running_corrects.double() / dataset_sizes['test']\n",
        "#   return loss_global, acc_global\n",
        "\n",
        "\n",
        "def test_model_gpu(model):\n",
        "\n",
        "    phase = 'test'\n",
        "    model.eval()\n",
        "\n",
        "    # initialisation des compteurs\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in tqdm(loader[phase]):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).cpu()\n",
        "\n",
        "    return running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "\n",
        "loss_global, acc_global = test_model_gpu(model)\n",
        "\n",
        "print(loss_global)\n",
        "print(acc_global)"
      ],
      "metadata": {
        "id": "-32wT1Sqw4dZ",
        "outputId": "a7a5c832-ae10-44fe-8ed7-ecf8f4382dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/313 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-3f416dfdc39d>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mloss_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_global\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-3f416dfdc39d>\u001b[0m in \u001b[0;36mtest_model_gpu\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 150, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhGIdbGx1oRn"
      },
      "source": [
        "**Question 8** Quel est l'effet de la fonction suivante sur un batch de cibles ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiZuZ2_p1xY2",
        "outputId": "218cb47f-01c7-410e-e0c5-797190d1ce54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8, 5, 1, 8, 2, 7, 2, 0, 5, 5, 4, 6, 5, 5, 3, 1, 6, 7, 4, 5, 4, 2, 2, 8,\n",
            "        7, 5, 0, 8, 9, 4, 9, 5], device='cuda:0')\n",
            "tensor([8, 0, 1, 8, 1, 8, 3, 5, 5, 4, 9, 6, 3, 4, 3, 1, 6, 7, 4, 0, 0, 2, 2, 6,\n",
            "        7, 5, 0, 8, 9, 4, 5, 5], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def flipping_label(labels, p):\n",
        "  #Sélection aléatoire des composantes\n",
        "  flip_probas = p * torch.ones(labels.shape)\n",
        "  flip_or_not = torch.bernoulli(flip_probas) == 1\n",
        "  random_labels = torch.randint(0,10,labels.shape).to(device)\n",
        "  labels[flip_or_not] = random_labels[flip_or_not]\n",
        "\n",
        "\n",
        "\n",
        "labels = torch.randint(0,10,(32,)).to(device)\n",
        "print(labels)\n",
        "\n",
        "# niveau de bruit :\n",
        "p = 0.5\n",
        "\n",
        "# Après bruitage :\n",
        "flipping_label(labels, p)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction permet de changer la cible avec une probabilité un demi, c'est-à-dire q'une cible a une chance sur deux de voir sa valeur changer selon une loi uniforme sur 0 à 9"
      ],
      "metadata": {
        "id": "7Xy3s-YCElza"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5gWTBWgt9O0"
      },
      "source": [
        "**Question 9** Définir une procédure d'entraînement \"bruitée\" à partir de flipping_labels() (ne bruiter que la phase d'entraînement). Quel est l'effet sur les performances en fonction du niveau de bruit ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_gpu_proba(model, loss_fn, optimizer, num_epochs, p):\n",
        "    # Record the starting time\n",
        "    since = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Iterate through training and validation phases\n",
        "        for phase in ['train', 'val']:\n",
        "            # Set the model to training mode during the training phase, and evaluation mode during validation\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Initialize counters for loss and correct predictions\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate through batches in the data loader\n",
        "            for inputs, labels in loader[phase]:\n",
        "                # Move inputs and labels to the specified device (GPU)\n",
        "                ### BEGIN SOLUTION\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                flipping_label(labels, p)\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Zero the gradients in the optimizer (same as in train_model())\n",
        "                ### BEGIN SOLUTION\n",
        "                optimizer.zero_grad()\n",
        "                ### END SOLUTION\n",
        "                # Forward pass: compute model outputs and predictions (same as in train_model())\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ### BEGIN SOLUTION\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    ### END SOLUTION\n",
        "                    # Backward pass and optimization step if in the training phase (same as in train_model())\n",
        "                    ### BEGIN SOLUTION\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    ### END SOLUTION\n",
        "                # Update counters\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                acc = torch.sum(preds == labels.data)\n",
        "                # The 'acc' tensor is distributed across different parts of the GPU\n",
        "                # Gather the 'acc' tensor on the CPU before accumulation\n",
        "                # running_corrects += ...\n",
        "                ### BEGIN SOLUTION\n",
        "                running_corrects += acc.cpu()\n",
        "                ### END SOLUTION\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # At the end of each epoch, save the best model:\n",
        "            if phase == \"val\" and epoch_acc > best_val_acc:\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    # Calculate and print the total training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn =  nn.CrossEntropyLoss()\n",
        "\n",
        "model = train_model_gpu_proba(model, loss_fn, optimizer, num_epochs=50, p = 0.5)"
      ],
      "metadata": {
        "id": "VzDVUqYzFjOb",
        "outputId": "67298926-fefa-47b2-c158-d5157217239e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.9365 Acc: 45.19%\n",
            "val Loss: 1.7617 Acc: 53.17%\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 1.8434 Acc: 51.34%\n",
            "val Loss: 1.7675 Acc: 53.45%\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 1.8387 Acc: 51.84%\n",
            "val Loss: 1.7429 Acc: 53.65%\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 1.8311 Acc: 52.23%\n",
            "val Loss: 1.7544 Acc: 53.29%\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 1.8334 Acc: 52.02%\n",
            "val Loss: 1.7576 Acc: 53.91%\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 1.8196 Acc: 52.74%\n",
            "val Loss: 1.7537 Acc: 53.73%\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 1.8236 Acc: 52.49%\n",
            "val Loss: 1.7315 Acc: 54.37%\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 1.8228 Acc: 52.56%\n",
            "val Loss: 1.7235 Acc: 54.34%\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 1.8110 Acc: 52.90%\n",
            "val Loss: 1.7675 Acc: 53.45%\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 1.8180 Acc: 52.74%\n",
            "val Loss: 1.7595 Acc: 52.88%\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 1.8119 Acc: 52.99%\n",
            "val Loss: 1.7544 Acc: 53.76%\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 1.8114 Acc: 52.95%\n",
            "val Loss: 1.7323 Acc: 53.77%\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 1.8093 Acc: 52.98%\n",
            "val Loss: 1.7257 Acc: 54.23%\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 1.8083 Acc: 53.22%\n",
            "val Loss: 1.7326 Acc: 54.22%\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 1.8124 Acc: 53.04%\n",
            "val Loss: 1.7533 Acc: 53.63%\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 1.8091 Acc: 52.96%\n",
            "val Loss: 1.7309 Acc: 53.82%\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 1.8081 Acc: 53.14%\n",
            "val Loss: 1.7257 Acc: 53.83%\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 1.8052 Acc: 53.26%\n",
            "val Loss: 1.7473 Acc: 53.66%\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 1.8198 Acc: 52.56%\n",
            "val Loss: 1.7093 Acc: 54.79%\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 1.8124 Acc: 52.99%\n",
            "val Loss: 1.7283 Acc: 53.75%\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 1.8075 Acc: 53.22%\n",
            "val Loss: 1.7160 Acc: 54.23%\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 1.8079 Acc: 53.16%\n",
            "val Loss: 1.7239 Acc: 54.18%\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 1.8138 Acc: 53.08%\n",
            "val Loss: 1.7169 Acc: 54.44%\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 1.7953 Acc: 53.48%\n",
            "val Loss: 1.7279 Acc: 54.00%\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 1.8021 Acc: 53.39%\n",
            "val Loss: 1.7210 Acc: 54.62%\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 1.8026 Acc: 53.42%\n",
            "val Loss: 1.7146 Acc: 54.52%\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 1.8042 Acc: 53.41%\n",
            "val Loss: 1.7303 Acc: 54.41%\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 1.8054 Acc: 53.03%\n",
            "val Loss: 1.7372 Acc: 53.68%\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 1.7987 Acc: 53.53%\n",
            "val Loss: 1.7372 Acc: 53.65%\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 1.7981 Acc: 53.52%\n",
            "val Loss: 1.7283 Acc: 53.82%\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 1.8155 Acc: 52.83%\n",
            "val Loss: 1.7258 Acc: 54.49%\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 1.7979 Acc: 53.50%\n",
            "val Loss: 1.7220 Acc: 54.59%\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 1.8066 Acc: 53.12%\n",
            "val Loss: 1.7214 Acc: 54.19%\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 1.7999 Acc: 53.29%\n",
            "val Loss: 1.7227 Acc: 54.20%\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 1.8046 Acc: 53.15%\n",
            "val Loss: 1.7336 Acc: 53.82%\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 1.7990 Acc: 53.50%\n",
            "val Loss: 1.7222 Acc: 54.43%\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 1.8080 Acc: 52.94%\n",
            "val Loss: 1.7219 Acc: 53.90%\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 1.8023 Acc: 53.16%\n",
            "val Loss: 1.7165 Acc: 54.43%\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 1.8018 Acc: 53.31%\n",
            "val Loss: 1.7173 Acc: 54.49%\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 1.7970 Acc: 53.32%\n",
            "val Loss: 1.7320 Acc: 53.87%\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 1.7959 Acc: 53.42%\n",
            "val Loss: 1.7224 Acc: 53.83%\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 1.7988 Acc: 53.37%\n",
            "val Loss: 1.7012 Acc: 55.17%\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 1.8005 Acc: 53.33%\n",
            "val Loss: 1.7115 Acc: 54.75%\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 1.7942 Acc: 53.66%\n",
            "val Loss: 1.7505 Acc: 53.01%\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 1.8067 Acc: 53.06%\n",
            "val Loss: 1.7112 Acc: 54.57%\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 1.7956 Acc: 53.55%\n",
            "val Loss: 1.7313 Acc: 53.52%\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 1.7987 Acc: 53.59%\n",
            "val Loss: 1.7239 Acc: 54.39%\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 1.7945 Acc: 53.79%\n",
            "val Loss: 1.7230 Acc: 54.07%\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 1.7956 Acc: 53.50%\n",
            "val Loss: 1.7064 Acc: 54.83%\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 1.8019 Acc: 53.22%\n",
            "val Loss: 1.7355 Acc: 53.42%\n",
            "Training complete in 15m 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA8klyqT7w7c"
      },
      "source": [
        "**Problème 2** Le chat perturbé\n",
        "\n",
        "\n",
        "Reprendre l'image de chat du TP2 et la bruiter de manière à ce que :\n",
        "- le chat soit encore parfaitement reconnaissable\n",
        "- le VGG16 vu au TP2 se trompe complètement de classe.\n",
        "\n",
        "Vous pourrez par exemple dégrader la résolution et modifier localement la valeur de certains pixels. En vous renseignant un peu sur les \"attaques adversariales\", vous verrez comment aborder le problème par des techniques d'optimisation bien choisies. \\\\\n",
        "L'image \"disrupted_cat.jpg\" du répertoire \"exercises\" fournit un exemple de solution. Les cellules ci-dessous permettent de le vérifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "1a5xCu_O_FCn",
        "outputId": "547bd3ca-09c0-4a18-9c75-196db90cb9e1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/relmonta/ml-student.git"
      ],
      "metadata": {
        "id": "FXzuQ5-SM093",
        "outputId": "2d403d08-02c8-409d-cda0-16b4599e0f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-student'...\n",
            "remote: Enumerating objects: 381, done.\u001b[K\n",
            "remote: Counting objects: 100% (171/171), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 381 (delta 117), reused 128 (delta 93), pack-reused 210\u001b[K\n",
            "Receiving objects: 100% (381/381), 48.56 MiB | 22.80 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ml-student/TP1"
      ],
      "metadata": {
        "id": "ZO_-LHHJM3G3",
        "outputId": "cd46c0c3-bff9-4ab3-816d-5a0c1dea7483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat.jpg  TP1_part1_corr.ipynb  TP1_part1.ipynb\tTP1_part2_corr.ipynb  TP1_part2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0bgOmbQOK5C7",
        "outputId": "20f8496f-6dab-4a99-fb89-622ca9100a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "model = model.cuda()\n",
        "softmx = nn.Softmax(dim=1).cuda()\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from PIL import Image\n",
        "# bornes sur les paramètres:\n",
        "# nombre de pixels à modifier\n",
        "Npix = 20\n",
        "Nc = 3\n",
        "bounds = np.array([(0,1), (0,1)] + [(-3., 3.) for m in range(Nc)])\n",
        "\n",
        "# cette fonction permet de dupliquer un vecteur N fois\n",
        "\n",
        "def repeat(x, N):\n",
        "  s = x.shape\n",
        "  x = x.reshape((1,*s)).repeat(N,axis=0).reshape((s[0]*N,-1))\n",
        "  return np.squeeze(x)\n",
        "\n",
        "print(bounds.shape)\n",
        "bounds = repeat(bounds, Npix)\n",
        "print(bounds.shape)\n",
        "\n",
        "# image\n",
        "s = 64\n",
        "path = 'ml-student/TP1/cat.jpg'\n",
        "image = Image.open(path).convert(\"RGB\")\n",
        "image = image.resize((s,s))\n",
        "img = transforms.ToTensor()(image)\n",
        "img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
        "# sortie brute\n",
        "img = img.unsqueeze(dim=0).cuda()\n",
        "\n",
        "mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "std = torch.tensor([0.229, 0.224, 0.225])"
      ],
      "metadata": {
        "id": "KgPfH-hhMk5c",
        "outputId": "912f908c-5631-42b3-85fb-b45922f7def1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 2)\n",
            "(100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cette fonction permet de modifier les valeurs des pixels donnés\n",
        "def update_pixels(img,x):\n",
        "  new_img = copy.deepcopy(img).cuda().detach()\n",
        "  for j in range(Npix):\n",
        "    coordx = round((s-1)*x[5*j])\n",
        "    coordy = round((s-1)*x[5*j + 1])\n",
        "    # la normalisation par l'écart type (std) + la moyenne assure que les valeurs données\n",
        "    # aux pixels modifiés ne soient pas aberrantes\n",
        "    newcolumn = torch.tensor([x[5*j + 2],x[5*j + 3],x[5*j + 4]]) * std + mean\n",
        "    new_img[0, :, coordx, coordy] = newcolumn.cuda()\n",
        "  return new_img\n",
        "\n",
        "# cette fonction permet de calculer la loss sur certaines probabilités de classification\n",
        "def loss_over_targets(x):\n",
        "  new_img = update_pixels(img,x)\n",
        "  output = softmx(model(new_img)).squeeze(dim=0)\n",
        "  #loss = -torch.log(output[286:287]).mean() + torch.log(output[281:286]).mean()\n",
        "  # 281,...,286 correspondent aux classes de chats\n",
        "  loss = torch.log(output[281:286]).mean()\n",
        "  return loss.cpu().item()\n",
        "\n",
        "\n",
        "# Cette fonction permet de calculer la prediction du model l'image modifiée\n",
        "def get_pred(x):\n",
        "  new_img = update_pixels(img, x)\n",
        "  output = softmx(model(new_img))\n",
        "  pred = torch.max(output, dim = 1)[1]\n",
        "  mean_proba = output[0,281:286].mean()\n",
        "  return pred.item(), new_img, mean_proba.item()\n"
      ],
      "metadata": {
        "id": "5yMpy7eFT-uq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exemple\n",
        "x0 = np.array([0.2,0.5,1.2,-1.2,-0.3])\n",
        "\n",
        "print(repeat(x0, Npix))\n",
        "print(loss_over_targets(repeat(x0, Npix)))"
      ],
      "metadata": {
        "id": "LZXd5LsAf30J",
        "outputId": "73d350b5-8b72-4121-94d4-77593ec9be00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2\n",
            " -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2\n",
            " -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5\n",
            "  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2\n",
            "  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3\n",
            "  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2\n",
            " -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2 -1.2 -0.3  0.2  0.5  1.2\n",
            " -1.2 -0.3]\n",
            "-4.375197887420654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import scipy as sc\n",
        "# Diffrential evolution est algorithme stochastique d'optimisation\n",
        "from scipy.optimize import differential_evolution as de\n",
        "\n",
        "# Nous allons chercher à trouver les pixels et la valeurs à modifier\n",
        "# pour minimiser les probabilités de classifier l'image comme étant un caht\n",
        "result = de(loss_over_targets, bounds = bounds, popsize = 400, mutation = 0.5, maxiter = 1, recombination = 0.05,  seed=1)\n",
        "\n",
        "# print(round((s-1)*result.x[0]))\n",
        "# print(round((s-1)*result.x[1]))\n",
        "# print(result.x[2:])\n",
        "cl_init, _, mean_proba_init = get_pred(repeat(x0,Npix))\n",
        "cl, new_img, mean_proba = get_pred(result.x)\n",
        "print(cl_init, mean_proba_init)\n",
        "print(cl, mean_proba)\n",
        "print(result.fun)\n"
      ],
      "metadata": {
        "id": "DO4LhQM9UCUl",
        "outputId": "3505ebab-7fda-41fc-f9eb-5fb87384d1ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281 0.18854497373104095\n",
            "478 0.06669550389051437\n",
            "-8.188455581665039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XlOFTHwj_fOZ"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None, save_path=None):\n",
        "    if save_path is not None:\n",
        "        torch.save(inp, save_path)\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(round((s-1)*result.x[0]))\n",
        "print(round((s-1)*result.x[1]))\n",
        "\n",
        "print(result.x[2:])\n",
        "\n",
        "cl, new_img = get_pred(result.x)\n",
        "print(cl)\n",
        "imshow(new_img.squeeze(dim=0).cpu())"
      ],
      "metadata": {
        "id": "8v3iChCeUGdw",
        "outputId": "90a6ea8d-a4fa-4c0f-a472-13de81dc24ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "6\n",
            "[ 0.17201936 -1.0210491   0.91123882  0.42352505  0.18979849 -1.99737049\n",
            " -1.69988264  0.14548844  0.83438709  0.55892702 -2.82417868 -2.65634738\n",
            "  0.67255811  0.9748513   0.48318814  1.66049423 -2.08977263 -1.29915365\n",
            "  0.76193684  0.87110042  2.64251931 -1.67664241 -0.21745681  0.92976958\n",
            "  0.13970375  2.01873362  2.34081689 -1.17804357  0.66696562  0.05545257\n",
            " -2.04837395 -0.93570721 -1.98029849  0.83561452  0.05746827 -1.74724892\n",
            " -0.30088305  0.536443    0.58210513  0.81835211 -0.64551438 -0.90989786\n",
            " -0.67203224  0.50055365  0.74405391  1.47410554 -0.95658008 -2.6581791\n",
            "  0.16611753  0.76165334  1.32551055 -0.12914898  2.14620973  0.36301936\n",
            "  0.75787551 -1.27838426 -0.68368644 -1.02720606  0.82823247  0.80827741\n",
            " -1.1944024   2.30775281 -0.61998134  0.18345209  0.34307205 -2.08270576\n",
            " -1.50891288  1.62970416  0.04126463  0.48784556 -1.24992245  0.91613368\n",
            "  2.98919035  0.10481774  0.09576569 -1.67827487 -2.44345732 -1.05848791\n",
            "  0.36499438  0.05850281  2.338427    1.44932475  1.43179509  0.93308968\n",
            "  0.79193606 -2.67844485 -0.22984134  2.7723133   0.71515767  0.46868899\n",
            "  2.8516558   0.2868624  -2.79525702  0.2568924   0.69474548 -0.14276525\n",
            "  2.42946257  2.75460216]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3a554febd518>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "wNi8jykKiLvR",
        "outputId": "fdd8540c-082e-45c6-8fad-d307d08102ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classe prédite : 333 (hamster)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## Après optimisation voici une configuration qui arrive à tromper le modèle\n",
        "path = 'Ou/est/disrupted_cat.jpg'\n",
        "dcat = torch.load(path)\n",
        "imshow(dcat)\n",
        "\n",
        "dcat = dcat.unsqueeze(dim=0).cuda()\n",
        "output_dcat = softmx(model(dcat)).squeeze(dim=0)\n",
        "pred_dcat = torch.max(output_dcat, dim=0)[1].item()\n",
        "print(\"classe prédite : \" + str(pred_dcat) + \" (hamster)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}