{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "**Fiche d'exercice n°1**\n",
        "\n",
        "Cette fiche d'exercices doit permettre de :\n",
        "- s'entraîner au devoir de janvier\n",
        "- compléter votre culture dans le domaine\n",
        "\n",
        "La correction sera mise à disposition autour du 11/11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "**Question 1** Nous avons vu qu'il était impossible de séparer les nuages de points du TP1/partie I/B avec un perceptron une couche. Mais c'est parce que nous nous sommes limités à deux prédicteurs, l'abscisse $x$ et l'ordonnée $y$. Quels autres prédicteurs peut-on utiliser pour résoudre le problème sans ajouter de couches au perceptron ?\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les prédicteurs que nous pouvons également utiliser seraient une combinaison linéaire des deux premiers. Par exemple, la somme de x et y."
      ],
      "metadata": {
        "id": "1ffltojcYmHG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4B0YORSkz1G"
      },
      "source": [
        "**Question 2** A quel modèle statistique correspond un perceptron à une couche avec une fonction d'activation sigmoïde ?\n",
        "Citer une bibliothèque python qui permet d'appliquer ce modèle à un jeu de données."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch bibliothèque permettant d'appliquer ce modèle"
      ],
      "metadata": {
        "id": "fPBCBrPZY97d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUCeXqO7icjq"
      },
      "source": [
        "**Question 3** Combien un VGG16 contient-il de paramètres dans les couches de convolutions ? Dans les couches complètement connectées ?\n",
        "Appuyer par un bout de code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn   # pre-defined layers\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# to load pre-trained models on ImageNet:\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "model = models.vgg16(pretrained = False)\n",
        "print(model)\n",
        "\n",
        "conv_weights = 0\n",
        "\n",
        "linear_weights = 0\n",
        "\n",
        "for module in model.modules():\n",
        "  if isinstance(module, nn.Conv2d):\n",
        "    for parameter in module.parameters():\n",
        "      conv_weights += torch.numel(parameter)\n",
        "  if isinstance(module, nn.Linear):\n",
        "    for parameter in module.parameters():\n",
        "      linear_weights += torch.numel(parameter)\n",
        "\n",
        "print(conv_weights)\n",
        "print(linear_weights)\n"
      ],
      "metadata": {
        "id": "kJYLstZba9dN",
        "outputId": "3d0e55b7-ff01-4bf5-c795-eb35c39e40de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "14714688\n",
            "123642856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjBFb83GmuEY"
      },
      "source": [
        "**Question 4** Visualiser la première couche d'un VGG entraîné sur ImageNet. Commenter."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained = True)\n",
        "first_layer = model.features[0].weight.data\n",
        "print(first_layer.shape)\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(first_layer.shape[0]):\n",
        "    plt.subplot(8, 8, i+1) #\n",
        "    plt.imshow(first_layer[i, 0, :, :], cmap='seismic')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IInv08pzdjAK",
        "outputId": "8afc55a5-3a10-43c7-8f81-106da52a1472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 3, 3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 64 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ0AAASXCAYAAABLKw4hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxSElEQVR4nO3ab9CldX3f8XPVxcE/MEJGA8Qi0YIKKoJCkUScLnERhxv5m9TljwgFBKkDmkFtBA5iiTAMa5AEhQYzKyHGKDS7DAqZgG7EwKoomDAq1qJRF0UWx2hLsfDrkz7/XcP1ua7fOTuv1+Mz8/3svdeec+97TldKKTMAAAAACPo3rQcAAAAAsO0RnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiFvV94Vd95ERZ2SUW/ZsPaHq/iOOaD2h6lWljH7j8q4b/cZQR7Ue0MP9rQf0cNwEz9NsNpvNdt99mjsDzP/lX1pPqJrfcEPrCXUnnDD6iWuvHf3EYGvOXPz30R1bD+hh56neo17wgmnuDDB/5JHWE6ounj3RekJVKduNfqPrLhj9xnDbtx7Qw92tB1SVsnH0G8vwPO255yWtJ1RtfnDxP5efN9FnXtetTHJniLvuGv/f1lC/8zv3tZ5QVcq+1df4phMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcav6v/Sx8VaknHVW6wVVN7Ue0MOrJrjx3tkRE1wZ5iO7bmw9oeqMLV3rCVXHTXTn3cf9YKJLT9+6dSutJ1T9/okntp5QtfcJJ4x+46tfHf3EYD9uPaCHo1oP6GHnie5c+b6fTnTp6fvJg60X1J30q9YLFsM73nFJ6wlV17x9c+sJVYdf9EetJyyIb7QesE34SOsBPcwnulP++bKJLj19830W//9R5eijW0/ooV44fNMJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgLiulFJ6vbBbGXvLYF/84sbWE6r2eEPXekLV7v0eiUF23HH0E4N94V8X/+9q/wsuaD2h7oMfnObO1q3T3Bng2s/s3HpC1f5nLv5z/9oJ3qOW4TPvZS9b/M+8b31r8d+jSrlkkjtd981J7gzzX1oP6OHS1gOqSnnl+Ed23XX8GwPNH3649YSq+de+1npC3f77j36i6x4b/cZQ73jHTq0nVF3z589sPaHuiScmOXPjjZOcGWTt509uPaHufe9rvaBu772rL/FNJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiulJKaT0CAAAAgG2LbzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABC3qu8Lu+69Y+4IeaD1gKrzztvYekLVlVeOf2Ovvca/MdSDD660ntDDp1oPqCrlOZPcuf76Sc4Mctppj7aeUFVef3TrCXWbNo1+4owzRj8x2HXXLf571EWzW1pPqJqXMs2drpvkzhDz7bdvPaFqw+OPt55QdeQUz9Qdd4x/Y6Du0HWtJ1SViw9oPaHuwgtHP9F1vxj9xnAntB7Qw3GtB1SV8rZpDt100zR3BuiO/WrrCVXHH39p6wlVn/50/TW+6QQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAXFdKKX1e+PKXjz1luNO+1bWeUPXi1gN6OKbfIzHM6tXj3xjoe3fe2XpC1YsPOKD1hLrNmyc503Urk9wZ5tLWA6oumr2q9YSq+QTvUbd2i/958ub77ms9oWrDvvu2nlB15BSfebPZUnzudXc+p/WEqnLxEnzuXXjh6Ce6bsPoN4Z7ovWAqvK801tPqHvssdFPHHPM6CcGu+Lmxf9cfvHhh7eeUHfrrdPcOeSQae4M8O7Xbmo9oWrdusX//00pG6uv8U0nAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOK6Ukrp9coNG0aeMtz8LW9pPaFqt9YDejij5yMxxNauG/3GUFe1HtDD/KSTWk+oW79+mjtPPTXNnQHu/6fF7/yv+ot3t55Qd+WVo594aAneo/Y4/vjWE+r+4R9aL6jbsmWSMx9cgmfqwre/vfWEqs2f+ETrCVUHTvB71DK8R9372fF/DkPdf+zi/xznEzxPswMPHP/GQPOvfKX1hKqjWg/o4dVTPE+z2Wy+BO9R9x+9+O9Rxx3XekHd2rX11yz+/4AAAAAAWDqiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHFdKaW0HgEAAADAtsU3nQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIhb1feFXbdlzB0hN7ce0MNdrQdUlfKXo9/ouh+OfmOoct6VrSdUzdetaz2hal7KNIfWr5/mzgDzt72t9YSqg2+b6O9rgDVrJjjyp386wZFhbtzpna0nVP38hK71hKqzJ3qP2muvSc4MsvbBxf/7enXrAT0cNcEz9bNu8f+urm49oIejWg/o4dUTPE+3L8Hz9NzWA3q4vfWAHqb6vfxZz5rkzCD/+77vtJ5Q9fhLX9p6QtX2PZ4p33QCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIG5V3xeWPQ4ec0fE/KGHWk+ounh2busJC+Ks1gOqtn5gY+sJVTuuW9d6wsL4zkEnt55QNf/Vca0n1N19R+sFPawe/8TLXz7+jYG+c2jXekLV6i+W1hMWxoMPrrSeUPX7/7z4f18b9ln8534Kz2w9oIe9Wg/o4dXbbdd6wkL4+ocX/9/+e/e8qfWEql8ce2zrCQvj8cdvaD2hqnvpX7eeUHVR6wE9zHu8xjedAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIhb1feF3UOvGHNHxHnn/c/WE+rWXdd6wULYfvuNrSdUXbcEf1Xv/dCHWk9YGG95S+sFdY8++uzWE6oeeWRd6wlVpawe/UZ3aBn9xlDlb/+29YSq7g0rrSdUlTLV59H+E915+vbZZ0vrCVXl9NNbT1gIV1yw+O9Rl1yy+P/+53ss/u+j35ngxvvet/h/V3etLP7f1YY3vrH1hIWx004ntp5Q9alPLf7G3zusaz0hwjedAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIjrSiml9QgAAAAAti2+6QQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQNyqvi+8qevG3BHx6v9RWk+oOuWU1gvqNm0a/8Z8CZ6n3T6++M/T2jMX/+f43DLNz7HrzpnkzhDHH3916wlVp/zN4j9Tb57gmfrYErxHbW09oIcnWg/oYT7Re9QDD0xyZpC9P39l6wlVV73nPa0nVL1rimfq3nvHvzFQ95qLWk/o4Q9aD6gq5cTxj+y00/g3hjrppNYLquYf/WjrCVVTfebN9ttvmjtDLMFz/+U772w9oergHs+UbzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAELeq7wsPGnNFyG+95JzWE3r4fusBPWwc/cJ8hx1GvzFUd+ZK6wlVZ86+1HpCVZns0uL/2/r03bu3nlA1bz2ghzdPcOOJP5nuyX26/vsNrRfUfeYrXesJC2OffRb/M+X5zx//83+os2fvaT1hMVxxResFVa9//eI/T7/7u60XLIbu50vwg/joEa0XVN1221WtJyyM7hsvbD2hh2taD6gq/+Hk1hMifNMJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgLiulFL6vHDedWNvGezg23r9UZo67LA/bD2hqpQrxj9yxhnj3xjqm99svaDqjrvvbj2hanW/t5jBuu7jk9wZ4u///szWE6pWP3R96wl1p546+omuWxn9xnDXtB5Q9ejs37aeULXzRO9Rhx8+yZlBLrus9YK6x/dd/N9HD5zgmVqG38v3aD2gh7WtB/TwzAmep657cvQbw93QekBVuewnrSfUnX/+JGd2332SM4P84JQLW0+oml9ySesJVfMe71G+6QQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAXFdKKa1HAAAAALBt8U0nAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4lb1feGpp445I+MTn1hpPaHqi1/c2HpC1SGHTHDkgQcmODLMfJ99Wk+oOvX7pfWEqt13n+jQrrtOdGiAJ59svaCqe+Tk1hOqSrli9Bvzrhv9xlDzXXZpPaHqIw8/3HpC1bllmvfRHyzBM3V96wE9zK++uvWEune+c/QTX12C5+m1S/B3deU557SeUPXuKd6jzj57/BsDddf8SesJVSsr27WeULVhwzR3Ni3Be9Qht93WekLdD3/YekFdj1Dkm04AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxHWllNLrlWvWjDxluHe97PbWE6qu+tbi/xxnt4//c+y6m0e/MdSuux7dekLVL3/ZekHdL34xzZ1fdt00hwbYYXZE6wk9XN16QFUpLxr/yOWXj39joB0/dH7rCVVX/evi/7s8peevQUPdc88kZwbZbrvWC+rOPbf1grpNm8a/cf31498Y6rTTVlpPqPr27JbWE6r2muA9ar4Ev0NdvBS/Q32o9YCqUvad5M5yPFNrW0+o2mGHv2w9oarP//V80wkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAuK6UUvq88L913dhbBvth6wE9nNp6QA+793skBum6Pxz9xnDfbj2gh//cekBVKWsmuTNfgveo+Z57tp5QteGK77SeUHXkkePf6LpHxz8y2CmtB1SVk3ZqPaFu/fpJzuy22yRnBtmyZaX1hB6uaT2gqpQXjn7jgSX4zNv7ySdbT6iaP+MZrSdUzSf4vfxjS/A8Hfmj8X8OQ+12yjS/8w5y++2TnOm6Yye5M8wTrQdUHXDAxtYTqjZvrr/GN50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiOtKKaX1CAAAAAC2Lb7pBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABA3Kq+L7y968bcEXFw6wE9nHx0aT2h6qabxr/RdSvjHxnsOa0H9HBo6wFVpZw+yZ2ue/skd4b5WesBVaefvrH1hKprrx3/xj33jH9jqIMO+lzrCT38WesBVaVM88zPl+D3qPkFF7SeUPWLSy5pPaFqxzL+73pd9/HRbwz12c+e2XpC1UPHLv6/y3dP8DzdvwTvTw/ftvj/hzrssGX4zDt7kjs77zzJmUEee+y7rSf0cF7rAVV9fo/yTScAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4lb1feGXx1wRcmDrAT3cfPNK6wk9bBz9wn77jX9jqHtveKD1hKp7H9+79YSFUXb4bOsJdS95SesFVfec1nrBYvjcQV3rCVWfbD2gh/VvLK0nLIz5W9/aekJVd8nXW0+oKj/5SesJC+KW1gOqrrjizNYTqr7wf7xHzWaz2U2tB/Rw8r9rvaCPz7Ue0MPZk1y55ppJzgzyB//3ntYTqv561eL/n7kP33QCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIK4rpZQ+L/xZ1429ZbAffK3XH6Wp17zmydYTqkp5xug3Pr0Ez9MDrQf0cETrAT28tt9bzGDzJXimDm49oIc1KyutJ9Rt2DD6iRuW4Hl6ResBPax5/uJ/Lv/0p9PcWYb3qPl997WeULV5331bT6g6cIrPvWV4nloP6GH/1gN6OHKK5+mqq8a/MdQ557ReUHXWOxf/+xzXXDPNnQ9+cJo7Qzx10eK/jz7x/sX/PerSS+uvWfx/GQAAAAAsHdEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAuK6UUlqPAAAAAGDb4ptOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxIlOAAAAAMSJTgAAAADEiU4AAAAAxK3q+8Ifd92YOyLmp5fWE6quu26l9YSqUjaOfqPrNox+Y6jf/u0jW0+o+t5Ba1tPqLvxxmnubNo0zZ1t3PwNb2g9oWpeJnivv+OO8W8MdPuhh7aeUDV/3eJ/Ln/5y9PcWYa3qCfesPi/671xdkTrCVVT/B41e93rxr8x0OHP+8fWE6o+//nPtZ5QVcrho9/ouhtGvzHU979/YusJVR/4QOsFdevXT3NnvgTt4KDWA3p400FLsPIf6+/1vukEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQFxXSim9XnnvvSNPGa57zSdbT+jhiNYDqko5dPQbXbcy+o2hTjppY+sJVcd8sms9oeqonm8xQ3Xdeye5M8wDrQdU/ehHi//c77bb+DeW4T3qotktrSdUnfXwNP/+h/jN35zo0H77TXTo6Zt/4xutJ1T9+PTFf6auvXb8G/Nu8T//5698ZesJVd03X9R6QlUp438ud92HR78x1EWz97eeUPWK1gN6OG6i38tnu+46zZ0BjnndltYTqr70pdYL6n760/prfNMJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgLiulFL6vHDedWNvGexZH+71R2nqsstaL6jbunX8G2vXjn9jqBt/tqb1hKr53/1d6wlV835vMYPdeuskZwbZZZfWC+pe9prFf69/9hTP1PXXj39jqLvvbr2g6vznXdt6QtXll09zp+senebQAEcf/RutJ1TdfPOftZ5QVcrZo9+4//7RTwz2pje1XlC3ZYvnaTabzbpuZfQbwx3SekBV+exLWk+oO+aYSc503XcnuTPMx1oP6OHbrQdUlbKx+hrfdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgTnQCAAAAIE50AgAAACBOdAIAAAAgriullNYjAAAAANi2+KYTAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxohMAAAAAcaITAAAAAHGiEwAAAABxq3q/8vzzR5wRcu65rRdUdb91T+sJVaUcPfqNrrtr9BvDfbj1gKqTTtrYekLV+vUTHVq9eqJD27b9f35H6wlV9947wZHbb5/gyDDzww5rPaHqyNYDeti/lGkO3bH4/7bmhx7aekLV/IADWk+o27x59BMbNox+YrAjfz7VLwBP387nntx6QtXWrePfmHfd+EcGWoL/ic4W/zeH2eyoiT7zpnhuh9pll9YL6n7965XWE6pKqf9/1DedAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIgTnQAAAACIE50AAAAAiBOdAAAAAIjrSimlzwv/V9eNvWWw//TWXn+Upv7qr1ZaT6gqZeP4R1avHv/GUM99busFdXvs0XpB3VVXTXLm1iV4j9rcekAPF8+OaD2haor3qKeW4Hl6xhL8Xf1qdkvrCVXP7vdr0GBXLcEz9a7tt289oep7jz/eekLViyd4pj6zBM/TP7Ue0IPPvP/v2mvHvzFQd+YEP4eBum7xNz711DR3Pr8E71Gb3r/47eCP//j41hOqSvmb6mt80wkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAONEJAAAAgDjRCQAAAIA40QkAAACAuK6UUvq8cN51Y28ZbG3rAT0ctFOvH3dTW7eOf+MvluB5eqj1gB4Oaj2ghzf1e4sZ7LtL8Ext33pADy+8667WE+oOPnj0EzcuwfP00H9d/M+TU/9o8X+Ou0z0HjV7wQumuTNA98i/bz2hqtzwH1tPqDvhhNFPrFkz+onBvvCF1gvqfv3rLa0nVJWy6/hH1q8f/8ZA3du+3npCDy9qPaCqlHMnubMM7eCshxf/96jzzmu9oO7GG+uv8U0nAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOJEJwAAAADiRCcAAAAA4kQnAAAAAOK6UkppPQIAAACAbYtvOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABAnOgEAAAAQJzoBAAAAECc6AQAAABD3/wCuPfAjcsR9PAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracteurs de contours et détecteurs de particularités (lignes...)"
      ],
      "metadata": {
        "id": "7j0o9RTIh7IX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfcRiTA2mzrp"
      },
      "source": [
        "**Question 5** Quel est l'effet d'un dropout sur les couches complètement connectées ? Illustrer sur un perceptron à une couche avec quelques lignes de codes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dropout permet de geler certains neurones pour éviter le surapprentissage."
      ],
      "metadata": {
        "id": "sfhK7k4diYtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class P1(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(P1, self).__init__()\n",
        "        self.fc = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Dot product and bias\n",
        "        x = self.fc(x)\n",
        "        # Activation\n",
        "        x = x.sigmoid()\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Vector of \"probabilities\" (cat: concatenation)\n",
        "        x = torch.cat((x, 1 - x), dim=1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "CqknqlLLio5y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-xSNmhpm1LB"
      },
      "source": [
        "**Problème 1** Classification avec cibles bruitées\n",
        "\n",
        "Les utilisateurs du Machine Learning font souvent face à un problème de qualité des cibles.\n",
        "Dans ce court problème, on se propose de mesurer l'effet de cibles bruitées sur les performances en généralisation d'un CNN.\n",
        "\n",
        "\n",
        "Pour une comparaison propre, nous allons d'abord scinder en trois jeux le dataset MNIST :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NozoimIfmkjc"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torch\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "root = '/content/drive/MyDrive/TP_ENM/data'\n",
        "\n",
        "#Définition des jeux d'apprentissage:\n",
        "tr=torchvision.transforms.Compose([\n",
        "   torchvision.transforms.ToTensor(),\n",
        "   torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "   ])\n",
        "\n",
        "\n",
        "ds_trainval = datasets.MNIST(root='MNIST', download=True, train=True)\n",
        "ds_test = datasets.MNIST(root='MNIST', download=True, train=False)\n",
        "\n",
        "\n",
        "\n",
        "len_trainval = len(ds_trainval)\n",
        "len_train = round(0.8 * len_trainval)\n",
        "len_val = len_trainval - len_train\n",
        "subset_train, subset_val = random_split(ds_trainval,\n",
        "                                [len_train, len_val],\n",
        "                                generator=torch.Generator().manual_seed(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rXc4EkTz0IFM"
      },
      "outputs": [],
      "source": [
        "#Split aléatoire en deux datasets (80% train, 20% val):\n",
        "class SubDataset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uOosklok0Lik"
      },
      "outputs": [],
      "source": [
        "ds = {}\n",
        "ds['train'] = SubDataset(subset_train, tr)\n",
        "ds['val'] = SubDataset(subset_val, tr)\n",
        "ds['test'] = ds_test\n",
        "loader = {x : DataLoader(ds[x], batch_size=32, shuffle=True, num_workers = 2) for x in ds.keys()}\n",
        "\n",
        "TrainLoader = loader['train']\n",
        "inputs, labels = next(iter(TrainLoader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ds['train']))\n",
        "\n",
        "print(len(ds['val']))\n",
        "\n",
        "print(len(ds['test']))"
      ],
      "metadata": {
        "id": "Sfv-ZsXdlCTc",
        "outputId": "b9db9e77-393c-4933-a403-abbd007c9a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48000\n",
            "12000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtQObOlvsZmK"
      },
      "source": [
        "**Question 6**  Quelles sont les tailles des différents jeux de données ? A quoi sert-il de fixer le générateur de nombres aléatoires dans random_split ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPUp4Ckqsvwq"
      },
      "source": [
        "**Question 7** Reprendre le CNN du TP2/partie1 et la fonction train_model_gpu vue au TP2/partie2.\n",
        "- Ajouter une procédure de sélection de modèle à partir des performances sur le jeu de validation.\n",
        "- Coder une fonction test_model_gpu() qui calcule la justesse sur le jeu de test.\n",
        "- Faire tourner l'apprentissage sur 50 époques, avec l'optimiser ADAM, paramétré de manière standard.\n",
        "\n",
        "Quelles sont les performances sur le jeu de test du modèle sélectionné ? \\\\\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\") # 0 is the index of the GPU\n",
        "  print(torch.cuda.get_device_name(device))\n",
        "else:\n",
        "  print('Change the runtime type to GPU')"
      ],
      "metadata": {
        "id": "Jy1pNZ7envOX",
        "outputId": "5c3c3249-5791-4341-9c11-e6120d4ef545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import copy\n",
        "\n",
        "N = 490\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(N, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, N)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        # Here, the log is applied after the softmax:\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "dataset_sizes = {'train':len(ds['train']), 'val':len(ds['val']), 'test':len(ds['test'])}\n",
        "\n",
        "def train_model_gpu(model, loss_fn, optimizer, num_epochs=1):\n",
        "    # Record the starting time\n",
        "    since = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Iterate through training and validation phases\n",
        "        for phase in ['train', 'val']:\n",
        "            # Set the model to training mode during the training phase, and evaluation mode during validation\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Initialize counters for loss and correct predictions\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate through batches in the data loader\n",
        "            for inputs, labels in loader[phase]:\n",
        "                # Move inputs and labels to the specified device (GPU)\n",
        "                ### BEGIN SOLUTION\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Zero the gradients in the optimizer (same as in train_model())\n",
        "                ### BEGIN SOLUTION\n",
        "                optimizer.zero_grad()\n",
        "                ### END SOLUTION\n",
        "                # Forward pass: compute model outputs and predictions (same as in train_model())\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ### BEGIN SOLUTION\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    ### END SOLUTION\n",
        "                    # Backward pass and optimization step if in the training phase (same as in train_model())\n",
        "                    ### BEGIN SOLUTION\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    ### END SOLUTION\n",
        "                # Update counters\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                acc = torch.sum(preds == labels.data)\n",
        "                # The 'acc' tensor is distributed across different parts of the GPU\n",
        "                # Gather the 'acc' tensor on the CPU before accumulation\n",
        "                # running_corrects += ...\n",
        "                ### BEGIN SOLUTION\n",
        "                running_corrects += acc.cpu()\n",
        "                ### END SOLUTION\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # At the end of each epoch, save the best model:\n",
        "            if phase == \"val\" and epoch_acc > best_val_acc:\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    # Calculate and print the total training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    # Return the trained model\n",
        "    return model, best_model_wts\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn =  nn.CrossEntropyLoss()\n",
        "\n",
        "model, best_model_wts = train_model_gpu(model, loss_fn, optimizer, num_epochs=50)\n"
      ],
      "metadata": {
        "id": "0cqO3zAdnLvZ",
        "outputId": "90a6b431-42f5-48b3-adf4-26e3efe48653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.3961 Acc: 87.36%\n",
            "val Loss: 0.0850 Acc: 97.32%\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.1795 Acc: 94.56%\n",
            "val Loss: 0.0610 Acc: 98.07%\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1380 Acc: 95.95%\n",
            "val Loss: 0.0546 Acc: 98.38%\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1173 Acc: 96.44%\n",
            "val Loss: 0.0517 Acc: 98.38%\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1037 Acc: 96.83%\n",
            "val Loss: 0.0481 Acc: 98.59%\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0942 Acc: 97.15%\n",
            "val Loss: 0.0507 Acc: 98.52%\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0861 Acc: 97.29%\n",
            "val Loss: 0.0484 Acc: 98.49%\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0790 Acc: 97.50%\n",
            "val Loss: 0.0469 Acc: 98.66%\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0772 Acc: 97.59%\n",
            "val Loss: 0.0431 Acc: 98.72%\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0729 Acc: 97.68%\n",
            "val Loss: 0.0457 Acc: 98.69%\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0707 Acc: 97.74%\n",
            "val Loss: 0.0450 Acc: 98.78%\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0657 Acc: 97.85%\n",
            "val Loss: 0.0442 Acc: 98.77%\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0654 Acc: 97.91%\n",
            "val Loss: 0.0450 Acc: 98.72%\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0619 Acc: 97.92%\n",
            "val Loss: 0.0500 Acc: 98.72%\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0608 Acc: 97.97%\n",
            "val Loss: 0.0385 Acc: 98.94%\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0587 Acc: 98.10%\n",
            "val Loss: 0.0483 Acc: 98.73%\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0555 Acc: 98.16%\n",
            "val Loss: 0.0463 Acc: 98.78%\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0559 Acc: 98.19%\n",
            "val Loss: 0.0461 Acc: 98.86%\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0533 Acc: 98.24%\n",
            "val Loss: 0.0517 Acc: 98.89%\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0500 Acc: 98.34%\n",
            "val Loss: 0.0422 Acc: 98.89%\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0499 Acc: 98.38%\n",
            "val Loss: 0.0501 Acc: 98.84%\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0478 Acc: 98.30%\n",
            "val Loss: 0.0453 Acc: 98.92%\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0499 Acc: 98.35%\n",
            "val Loss: 0.0521 Acc: 98.87%\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0451 Acc: 98.45%\n",
            "val Loss: 0.0506 Acc: 98.82%\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0457 Acc: 98.47%\n",
            "val Loss: 0.0475 Acc: 98.94%\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0461 Acc: 98.44%\n",
            "val Loss: 0.0483 Acc: 98.91%\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0427 Acc: 98.49%\n",
            "val Loss: 0.0486 Acc: 98.93%\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0429 Acc: 98.50%\n",
            "val Loss: 0.0534 Acc: 98.87%\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0431 Acc: 98.51%\n",
            "val Loss: 0.0531 Acc: 98.90%\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0437 Acc: 98.59%\n",
            "val Loss: 0.0506 Acc: 98.92%\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0441 Acc: 98.50%\n",
            "val Loss: 0.0558 Acc: 98.83%\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0415 Acc: 98.62%\n",
            "val Loss: 0.0542 Acc: 98.85%\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0391 Acc: 98.64%\n",
            "val Loss: 0.0543 Acc: 98.89%\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0419 Acc: 98.60%\n",
            "val Loss: 0.0597 Acc: 98.89%\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0389 Acc: 98.64%\n",
            "val Loss: 0.0510 Acc: 98.97%\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0401 Acc: 98.64%\n",
            "val Loss: 0.0564 Acc: 98.77%\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0420 Acc: 98.53%\n",
            "val Loss: 0.0505 Acc: 98.89%\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0393 Acc: 98.63%\n",
            "val Loss: 0.0609 Acc: 98.76%\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0416 Acc: 98.62%\n",
            "val Loss: 0.0595 Acc: 98.88%\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0363 Acc: 98.69%\n",
            "val Loss: 0.0593 Acc: 98.90%\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0384 Acc: 98.64%\n",
            "val Loss: 0.0611 Acc: 98.89%\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0409 Acc: 98.66%\n",
            "val Loss: 0.0650 Acc: 98.78%\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0376 Acc: 98.69%\n",
            "val Loss: 0.0617 Acc: 98.78%\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0346 Acc: 98.83%\n",
            "val Loss: 0.0609 Acc: 98.96%\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0370 Acc: 98.78%\n",
            "val Loss: 0.0660 Acc: 98.83%\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0357 Acc: 98.82%\n",
            "val Loss: 0.0624 Acc: 98.93%\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0374 Acc: 98.76%\n",
            "val Loss: 0.0633 Acc: 98.80%\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0365 Acc: 98.76%\n",
            "val Loss: 0.0594 Acc: 98.91%\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0364 Acc: 98.71%\n",
            "val Loss: 0.0648 Acc: 98.83%\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0347 Acc: 98.83%\n",
            "val Loss: 0.0657 Acc: 98.83%\n",
            "Training complete in 16m 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "TestLoader = loader['test']\n",
        "\n",
        "def test_model_gpu(model, loss_fn):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for input, label in loader['test']:\n",
        "      input = input.to(device)\n",
        "      label = label.to(device)\n",
        "      output = model(input)\n",
        "      loss = loss_fn(output, label)\n",
        "      _, preds = torch.max(output, 1)\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      acc = torch.sum(preds == labels.data)\n",
        "      acc = acc.to('cpu')\n",
        "      running_corrects += acc\n",
        "    loss_global = running_loss / dataset_sizes['test']\n",
        "    acc_global = running_corrects.double() / dataset_sizes['test']\n",
        "    return loss_global, acc_global\n",
        "\n",
        "loss_global, acc_global = test_model_gpu(model, loss_fn)\n",
        "\n",
        "print(loss_global)\n",
        "print(acc_global)"
      ],
      "metadata": {
        "id": "-32wT1Sqw4dZ",
        "outputId": "75735309-db22-46ec-f4a6-34b5a8fab767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-09b8b30d0516>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTestLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 150, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhGIdbGx1oRn"
      },
      "source": [
        "**Question 8** Quel est l'effet de la fonction suivante sur un batch de cibles ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "OiZuZ2_p1xY2",
        "outputId": "0e959a3c-7b2e-47e4-e9c6-1159d5496c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 7, 8, 9, 6, 1, 4, 1, 0, 5, 4, 6, 4, 4, 0, 2, 7, 8, 5, 2, 5, 7, 8, 7,\n",
            "        5, 9, 7, 3, 3, 0, 5, 6], device='cuda:0')\n",
            "tensor([ True,  True, False, False, False,  True, False, False,  True,  True,\n",
            "        False,  True,  True,  True, False, False,  True,  True,  True, False,\n",
            "        False, False,  True,  True, False, False,  True,  True,  True,  True,\n",
            "         True, False])\n",
            "tensor([0, 4, 8, 9, 6, 5, 4, 1, 1, 2, 4, 0, 3, 4, 0, 2, 4, 3, 8, 2, 5, 7, 4, 7,\n",
            "        5, 9, 0, 7, 8, 1, 7, 6], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def flipping_label(labels, p):\n",
        "  #Sélection aléatoire des composantes\n",
        "  flip_probas = p * torch.ones(labels.shape)\n",
        "  flip_or_not = torch.bernoulli(flip_probas) == 1\n",
        "  print(flip_or_not)\n",
        "  random_labels = torch.randint(0,10,labels.shape).to(device)\n",
        "  labels[flip_or_not] = random_labels[flip_or_not]\n",
        "\n",
        "\n",
        "\n",
        "labels = torch.randint(0,10,(32,)).to(device)\n",
        "print(labels)\n",
        "\n",
        "# niveau de bruit :\n",
        "p = 0.5\n",
        "\n",
        "# Après bruitage :\n",
        "flipping_label(labels, p)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction permet de changer la cible avec une probabilité un demi, c'est-à-dire q'une cible a une chance sur deux de voir sa valeur changer selon une loi uniforme sur 0 à 9"
      ],
      "metadata": {
        "id": "7Xy3s-YCElza"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5gWTBWgt9O0"
      },
      "source": [
        "**Question 9** Définir une procédure d'entraînement \"bruitée\" à partir de flipping_labels() (ne bruiter que la phase d'entraînement). Quel est l'effet sur les performances en fonction du niveau de bruit ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_gpu_proba(model, loss_fn, optimizer, num_epochs=1, p):\n",
        "    # Record the starting time\n",
        "    since = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Iterate through training and validation phases\n",
        "        for phase in ['train', 'val']:\n",
        "            # Set the model to training mode during the training phase, and evaluation mode during validation\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Initialize counters for loss and correct predictions\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate through batches in the data loader\n",
        "            for inputs, labels in loader[phase]:\n",
        "                # Move inputs and labels to the specified device (GPU)\n",
        "                ### BEGIN SOLUTION\n",
        "                inputs = inputs.to(device)\n",
        "                flipping_label(labels, p)\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Zero the gradients in the optimizer (same as in train_model())\n",
        "                ### BEGIN SOLUTION\n",
        "                optimizer.zero_grad()\n",
        "                ### END SOLUTION\n",
        "                # Forward pass: compute model outputs and predictions (same as in train_model())\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ### BEGIN SOLUTION\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    ### END SOLUTION\n",
        "                    # Backward pass and optimization step if in the training phase (same as in train_model())\n",
        "                    ### BEGIN SOLUTION\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    ### END SOLUTION\n",
        "                # Update counters\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                acc = torch.sum(preds == labels.data)\n",
        "                # The 'acc' tensor is distributed across different parts of the GPU\n",
        "                # Gather the 'acc' tensor on the CPU before accumulation\n",
        "                # running_corrects += ...\n",
        "                ### BEGIN SOLUTION\n",
        "                running_corrects += acc.cpu()\n",
        "                ### END SOLUTION\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # At the end of each epoch, save the best model:\n",
        "            if phase == \"val\" and epoch_acc > best_val_acc:\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    # Calculate and print the total training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn =  nn.CrossEntropyLoss()\n",
        "\n",
        "model = train_model_gpu_proba(model, loss_fn, optimizer, num_epochs=50, p = 0.5)"
      ],
      "metadata": {
        "id": "VzDVUqYzFjOb",
        "outputId": "d4d82975-9997-4d14-e2df-c5a395b102be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-190c00ff7b3a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def train_model_gpu_proba(model, loss_fn, optimizer, num_epochs=1, p):\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA8klyqT7w7c"
      },
      "source": [
        "**Problème 2** Le chat perturbé\n",
        "\n",
        "\n",
        "Reprendre l'image de chat du TP2 et la bruiter de manière à ce que :\n",
        "- le chat soit encore parfaitement reconnaissable\n",
        "- le VGG16 vu au TP2 se trompe complètement de classe.\n",
        "\n",
        "Vous pourrez par exemple dégrader la résolution et modifier localement la valeur de certains pixels. En vous renseignant un peu sur les \"attaques adversariales\", vous verrez comment aborder le problème par des techniques d'optimisation bien choisies. \\\\\n",
        "L'image \"disrupted_cat.jpg\" du répertoire \"exercises\" fournit un exemple de solution. Les cellules ci-dessous permettent de le vérifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a5xCu_O_FCn",
        "outputId": "30300fc6-c9ef-44ee-ebfc-e1078eaead24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bgOmbQOK5C7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "model = model.cuda()\n",
        "softmx = nn.Softmax(dim=1).cuda()\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlOFTHwj_fOZ"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None, save_path=None):\n",
        "    if save_path is not None:\n",
        "        torch.save(inp, save_path)\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "wNi8jykKiLvR",
        "outputId": "fdd8540c-082e-45c6-8fad-d307d08102ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classe prédite : 333 (hamster)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## Après optimisation voici une configuration qui arrive à tromper le modèle\n",
        "path = 'Ou/est/disrupted_cat.jpg'\n",
        "dcat = torch.load(path)\n",
        "imshow(dcat)\n",
        "\n",
        "dcat = dcat.unsqueeze(dim=0).cuda()\n",
        "output_dcat = softmx(model(dcat)).squeeze(dim=0)\n",
        "pred_dcat = torch.max(output_dcat, dim=0)[1].item()\n",
        "print(\"classe prédite : \" + str(pred_dcat) + \" (hamster)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}